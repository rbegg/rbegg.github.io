<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://rbegg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rbegg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-20T20:48:17+00:00</updated><id>https://rbegg.github.io/feed.xml</id><title type="html">Augmented Development</title><subtitle>A pragmatic approach to pair programming with AI to accelerate my learning to deliver more with less. </subtitle><entry><title type="html">Containerized Insights</title><link href="https://rbegg.github.io/blog/2025/Containerized-insight/" rel="alternate" type="text/html" title="Containerized Insights"/><published>2025-10-16T16:00:00+00:00</published><updated>2025-10-16T16:00:00+00:00</updated><id>https://rbegg.github.io/blog/2025/Containerized-insight</id><content type="html" xml:base="https://rbegg.github.io/blog/2025/Containerized-insight/"><![CDATA[<p>Discuss how the hands on experience has lead to some key insights …</p>]]></content><author><name></name></author><category term="insights"/><summary type="html"><![CDATA[Insights from building and deploying containers for Max's services]]></summary></entry><entry><title type="html">Beyond the Hype: What’s Working for Me in AI Pairing</title><link href="https://rbegg.github.io/blog/2025/Whats-working-for-me/" rel="alternate" type="text/html" title="Beyond the Hype: What’s Working for Me in AI Pairing"/><published>2025-10-16T16:00:00+00:00</published><updated>2025-10-16T16:00:00+00:00</updated><id>https://rbegg.github.io/blog/2025/Whats-working-for-me</id><content type="html" xml:base="https://rbegg.github.io/blog/2025/Whats-working-for-me/"><![CDATA[<p>A couple of months ago, I set out to build Max, an AI assistant for seniors. I explicitly decided to ignore both the hype and the doom surrounding AI coding agents and simply get to work. Along the way, I discovered what, for me, is a key to success.</p> <p>My many interactions with Gemini 2.5 Pro range from amazing to clearly wrong and disappointing. But the real insight and progress came from all the interactions that happened in between those two extremes, and no small amount of perseverance.</p> <h2 id="the-knowledge-challenge">The Knowledge Challenge</h2> <p>The project itself is complex, requiring me to learn about:</p> <ul> <li>Capturing audio and voice detection</li> <li>Converting that speech to text</li> <li>Analyzing the text with an LLM</li> <li>Determining appropriate data sources and generating responses</li> <li>Converting the text response back into speech</li> </ul> <p>Each of these topics involves researching tools, choosing between robust, complex solutions and simpler, build-it-yourself approaches, creating a proof of concept, and integrating it into the larger project.</p> <p>In addition to the core project features, there is a lot of infrastructure (building, testing, deploying, etc.) to put in place. Is crucial to learn and apply best practices as the project begins to take shape and increase in complexity.</p> <p>The journey has triggered me to reflect on how I and teams I have worked with in the past learn.</p> <h2 id="how-we-used-to-learn">How We Used to Learn</h2> <p>I have observed many cycles of new tools and frameworks promising to improve efficiency and reduce maintenance costs, but that gain is often diminished by the steep learning curve and ongoing complexity. It is also challenging to pick a stable solution you can rely on long-term, and does not cause excessive bloat.</p> <p>In order to get started, it is typical to find <strong>tutorials</strong> that walk you through a manageable (i.e. trivial) example. If you’re lucky, you can then find a complete project that’s close enough to your own goals that it can bootstrap your project. After a few refactoring loops, you either have a workable <strong>baseline</strong> or you’ve learned enough to abandon that approach and start over.</p> <p>On the flip side, I’ve seen many teams fall into the <em>custom code trap</em>. They decide their use case is simpler and a custom solution will be faster. While this sometimes works, in my experience, additional requirements are discovered and the custom solution grows in complexity until it’s obvious the existing framework would have been the better choice.</p> <p>The root issue is the tool/framework has evolved to handle a broad set of complex issues that are hard to appreciate without the knowledge gained from experience. We learn best when we start with simple solutions, and then iterate through a series of improvements. Over time, this knowledge evolves into best practices, design guidelines or other terms meant to captured generalized knowledge.</p> <h2 id="what-changes-with-an-ai-agent">What Changes with an AI Agent</h2> <p>AI agents are clearly a great replacement for internet searches, providing summaries or helping to debug specific problems. Troubleshooting in general is a fantastic application of AI tools, as they can process large logs far faster than a human. There’s no surprising insight here.</p> <p>Where I found initial success was asking the agent to generate a workable baseline, but only after I had done a quick tutorial. That initial bit of learning allowed me to provide much better context for my request.</p> <p>What really drove my productivity was this cycle:</p> <ul> <li>Generate a stand-up a baseline solution for one of the many project components (grab a chunk of audio in a browser)</li> <li>Resolve blocking issues and achieve some early success (send audio over websocket)</li> <li>Prioritize the areas to focus on understanding (websockets vs http requests, binary vs text)</li> <li>Use insight to prioritize refactoring (using a queue here may trigger refactoring elsewhere)</li> <li>Repeat for the next feature (send audio to speech-to-text service)</li> </ul> <p>In other words, iterative development, balancing feature progress with good design refactoring, pair coding with an AI agent.</p> <h2 id="the-key-to-success">The Key to Success</h2> <p>My key takeaway wasn’t about the tools or even how to craft good prompts. Rather, it was realizing my productivity was driven by my <strong>intent to learn</strong>. I wasn’t just trying to complete an assignment or get code working to meet a deadline.</p> <p>The more I learned and mastered the subjects:</p> <ul> <li>The more able I was to determine when to reject a solution from the AI.</li> <li>It became more obvious what needed refactoring.</li> <li>I was aware of better follow-up questions to ask.</li> </ul> <p>It was amusing and insightful to realize how the agent would readily agree the code it just wrote wasn’t very good and would suggest improvements—but only once I started asking more informed questions. Gemini reminded me of a very confident senior developer, who always had an answer ready, but was not always right. However, Gemini also has a lot more patience than most senior developers.</p> <p>To get a more realistic experience, I may try setting a system prompt along the lines of:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are a grumpy experienced senior developer, who just wants to get back to writing their own code.
Be stingy with your compliments so they mean more.
</code></pre></div></div> <p>Overall, approaching the AI agent as a partner for my own learning, rather than just a code-generator, made all the difference. It is not just helping develop the project; it is supercharging my own capacity to learn and deliver.</p>]]></content><author><name></name></author><category term="ai-pairing"/><summary type="html"><![CDATA[How Google Gemini has supercharged my learning]]></summary></entry><entry><title type="html">Why I’m Building Max</title><link href="https://rbegg.github.io/blog/2025/why-im-building-Max/" rel="alternate" type="text/html" title="Why I’m Building Max"/><published>2025-10-16T15:09:00+00:00</published><updated>2025-10-16T15:09:00+00:00</updated><id>https://rbegg.github.io/blog/2025/why-im-building-Max</id><content type="html" xml:base="https://rbegg.github.io/blog/2025/why-im-building-Max/"><![CDATA[<p>My mission is to create ‘Max’—a viable, locally-hosted AI assistant—to help seniors who feel left behind by technology.</p> <p>I’ve witnessed how quality of life suffers when technology becomes a barrier, preventing them from:</p> <ul> <li>Operating a smart TV</li> <li>Messaging, calling or video-chatting with family and friends</li> <li>Managing appointments or navigating their environment</li> </ul> <p>The initial focus/priority is on the seniors struggling with mild to moderate dementia.</p> <h2 id="core-principles">Core Principles</h2> <ol> <li>Max must be capable of running on locally deployed hardware with all context data and collected data kept locally.</li> </ol> <ul> <li>This is the best way to keep the user’s best interests in mind</li> <li>Secure cloud deployments may be acceptable in some cases, but it must not be dependent on any entity.</li> <li>A working assumption is using current consumer GPUs will be a viable stand-in for the expected availability of more compact HW solutions</li> </ul> <ol> <li>Max will require a family member, or other trusted support person to configure and manage the deployed solution.</li> </ol> <ul> <li>This role’s main task is to load in relevant context data - daily schedule, personal contacts, family tree, etc., so Max can digest it.</li> <li>Remote access is required, and must be secure.</li> <li>Passkeys stored locally should help with managing access to various services (streaming, msging, video calling etc.)</li> <li>Summaries of Max’s interactions and Audit capabilities should be included and made available.</li> </ul> <ol> <li>Max must restrict interaction to the provided context, and not expose a general chatbot experience.</li> </ol> <p>-</p>]]></content><author><name></name></author><category term="max-project"/><summary type="html"><![CDATA[An Ethical AI Assistant for a Better Quality of Life]]></summary></entry></feed>